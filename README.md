# Implicit Bias-Like Patterns in Reasoning Models

Paper and related materials for [Lee](https://lee-messi.github.io/) and [Lai](https://sites.wustl.edu/calvinlai/) (2025). The abstract for the paper is as follows:

> Implicit bias refers to automatic or spontaneous mental processes that shape perceptions, judgments, and behaviors. Previous research examining `implicit bias' in large language models (LLMs) has often approached the phenomenon differently than how it is studied in humans by focusing primarily on model outputs rather than on model processing. To examine model processing, we present a method called the Reasoning Model Implicit Association Test (RM-IAT) for studying implicit bias-like patterns in reasoning models: LLMs that employ step-by-step reasoning to solve complex tasks. Using this method, we find that reasoning models require more tokens when processing association-incompatible information compared to association-compatible information. These findings suggest AI systems harbor patterns in processing information that are analogous to human implicit bias. We consider the implications of these implicit bias-like patterns for their deployment in real-world applications. 

Please feel free to send me an [email](mailto:hojunlee@wustl.edu), or open an "Issue" [here](https://github.com/lee-messi/RM-IAT/issues). 

## Data Availability Statement

All data and code necessary to reproduce the results presented in this paper are publicly available in this repository. This includes the data collection code, raw data, and analysis scripts used in our study. No additional data or resources beyond those contained in this repository are required to replicate our findings.

